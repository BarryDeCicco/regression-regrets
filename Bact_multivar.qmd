#  Multivariate analyses

```{r, echo = FALSE, message = FALSE, warning = FALSE }
library(tidyr)
library(dplyr)
library(ggplot2)
library(purrr)
library(tidyselect)
library(corrr) ## tidy correlation
library(patchwork)
library(ggpubr)
library(here)
source(here("R", "fun_compare_dist_plot.R"))
source(here("R", "fun_compare_mult_dists.R"))
source(here("R", "fun_ida_trans.R"))

## Load the datasets - make sure to load the correct ADLB2 
## TODO: have a make workflow to ensure depencies run in correct order

ADSL <- readRDS(here::here("data", "ADSL_01.rds"))
ADLB <- readRDS(here::here("data", "ADLB_02.rds"))

```



## V1: Association with structural variables

A scatterplot of each predictor with age, with different panels for males and females have been constructed. Associated Spearman correlation coefficients have been computed.

### Key predictors


```{r mvi03, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3}
#| layout-ncol: 4

## Join with ADSL for structural variables 
ADSL01 <-
  ADSL |> 
  select(USUBJID, AGEGR01C, AGE, SEXC, SEX) 

dat <- ADLB |> 
  left_join(ADSL01, by = "USUBJID") 

## plots for key predictors
key_predictors <- dat |> 
  filter(!PARAMCD == "AGE") |>
  filter(KEY_PRED_FL02 == "Y") |>
  group_by(PARAMCD) |>
  group_map(~ plot_assoc_by(.x), .keep = TRUE)

## print out. TODO: ask GH which plots to save
for (plts in key_predictors) {
  print(plts)
}

```


### Predictors of medium importance

```{r mvi04, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3}
#| layout-ncol: 4 

medium_predictors <- dat |> 
  filter(!PARAMCD == "AGE") |>
  filter(MED_PRED_FL02 == "Y") |>
  group_by(PARAMCD) |>
  group_map(~ plot_assoc_by(.x), .keep = TRUE)

for (plts in medium_predictors) {
  print(plts)
}

```

### Remaining predictors

```{r mvi05, message=FALSE, warning=FALSE, echo=FALSE, fig.height=3}
#| layout-ncol: 4 

remain_predictors <- dat |> 
  filter(!PARAMCD == "AGE") |>
  filter( REM_PRED_FL02 == "Y") |>
  group_by(PARAMCD) |>
  group_map(~ plot_assoc_by(.x), .keep = TRUE)


for (plts in remain_predictors) {
  print(plts)
}

```


## V2: Correlation coefficients between all predictors


```{r}
#corrs <- c_bact %>%
#    dplyr::select(all_of(variables)) %>%
#      cor(use="pairwise.complete.obs", method="spearman")
# corrs <-
#   wide |> 
#   select(-USUBJID) |>
#   cor(use="pairwise.complete.obs", method="spearman")
# 


## tidy parameters in to a wide data set
wide <- dat |>
  filter(KEY_PRED_FL02 == "Y" | MED_PRED_FL02 == "Y" | REM_PRED_FL02 == "Y") |>
  select(USUBJID, PARAMCD, AVAL, SEX) |>
  pivot_wider(names_from = PARAMCD, values_from = AVAL, values_fill = NA) 

spearman_corr <- 
  wide |> 
  select(-USUBJID) |>
  correlate(use = "pairwise.complete.obs",
            method = "spearman",
            diagonal = NA)


# spearman_corr |> glimpse()

```

The Spearman correlation coefficients are depicted in a quadratic heat map:

```{r}

# library(ggcorrplot)
#ggcorrplot(corrs, tl.cex=5, tl.srt=90)
# Get the lower triangle
# ggcorrplot(corrs, hc.order = TRUE, type = "lower",
     # outline.col = "white")

theme_set(theme_minimal(base_size = 6))


gg <- autoplot(spearman_corr,
         method = "PCA",
         triangular = "lower",
         barheight = 10) +
  theme(
    axis.text.x = ggplot2::element_text(angle = 45, vjust = 1, hjust = 1, size = 4),
    axis.text.y = ggplot2::element_text(angle = 45, vjust = 1, hjust = 1, size = 4)
  )

gg

spearman_corr |>
  shave() |>
  rplot(print_cor = TRUE)


# wide |> 
#   select(-USUBJID) |>
#   correlate(use = "pairwise.complete.obs",
#             method = "spearman") |>
#   network_plot()
# 
# 
# x <- correlate(wide |> select(-USUBJID) )
# network_plot(x)

```


```{r}
spearman_corr |>
  shave(upper = TRUE) |>
  fashion() |>
  gt::gt()
```



### VE1: Comparing nonparametric and parametric predictor correlation

```{r}
# differences of pearson and spearman correlations to check for outliers
#corrp <- c_bact %>%
#    dplyr::select(all_of(variables)) %>%
#      cor(use="pairwise.complete.obs", method="pearson")


a <- spearman_corr |>  as_matrix()

pearson_corr <- 
  wide |> 
  select(-USUBJID) |>
  correlate(use = "pairwise.complete.obs",
            method = "pearson",
            diagonal = NA)

b <- pearson_corr |> as_matrix()

corrd <- a - b

corr_difference <- corrd |> as_cordf()

autoplot(corr_difference)


corr_difference_conditional <-
  corr_difference |> 
  stretch() |>
  mutate(r = if_else(abs(r) > 0.1, r, 0)) |>
  retract() |>
  as_cordf()

autoplot(corr_difference_conditional)


corr_difference_conditional |>
  shave() |>
  rplot(print_cor = TRUE)

# sparsified differences of correlation coefficients
#corrd_sp <- corrd
#corrd_sp[abs(corrd)<0.1] <-0

#ggcorrplot(corrd_sp, tl.cex=5, tl.srt=90)

#ggcorrplot(corrd_sp, type = "lower", outline.col = "white")


```
Predictor pairs for which Spearman and Pearson correlation coefficients differ by more than 0.1 correlation units will be depicted in scatterplots:

```{r}
#for(j in 1:(length(variables)-1)){
#  for(jj in (j+1):(length(variables))){
#    if(abs(corrd[j, jj])>0.1) print(ggplot(data=c_bact, #mapping=aes(x=.data[[variables[j]]],y=.data[[variables[jj]]]))+ geom_point(alpha = alpha_value) +
#    theme_minimal())
#  }
#}

## COMMENT @Mark can we print pearson and spearman correlation coefficients into/over the graphs?

count <- 0

for (i in 1:49) {
  
  for (j in (i+1):50) {
    if (abs(corrd[i , j]) > 0.1) {
      
      count <- count + 1 
        
      print(paste0(i, " ", j, " ", corrd[i , j]))
      print(paste0(attr(corrd, "dimnames")[[1]][i], " vs ", attr(corrd, "dimnames")[[2]][j]))
      
      x_lab <- attr(corrd, "dimnames")[[1]][i]
      y_lab <- attr(corrd, "dimnames")[[2]][j]
      
      dat <- 
        wide |>
        select(all_of(c(x_lab, y_lab))) |>
        tidyr::drop_na()
      
      #print(dat |>
      #  ggplot(mapping = aes(x = dat[[x_lab]], y = dat[[y_lab]])) +
      #    geom_point())
      
      
      
    }
  }
}


count

```


### VE2: Variable clustering

A variable clustering analysis has been performed to evaluate which predictors are closely associated. The dendrogram groups predictors by their correlation.

```{r}

dat <- wide |> select(-USUBJID)

vc_bact<-Hmisc::varclus(as.matrix(dat))
plot(vc_bact, cex=0.7, hang=0.01)




```

In the following scatterplots we show predictor pairs with Spearman correlation coefficients greater than 0.8:

```{r}
#for(j in 1:(length(variables)-1)){
#  for(jj in (j+1):length(variables)){
#    if(abs(corrs[j, jj])>0.8){
#      print(ggplot(c_bact, aes(.data[[variables[j]]], .data[[variables[jj]]]))+geom_point(alpha = alpha_value, shape = 20))
#    }
#  }
#}

## see loop above - try to do this in a tidy way..

```

### VE3: Redundancy

Variance inflation factors (VIF) will be computed between the candidate predictors. This will be done for the three possible candidate models, and using all complete cases in the respective candidate predictor sets.  Since $VIF = (1-R^2)^{-1}$, we also report the multiple R-squared values. Redundancy was further  explored by computing parametric additive models for each predictor in the key predictor model and the extended predictor model. VIFs and multiple $R^2$ are reported from those models, again for the three predictor sets.


#### VIF for key predictor model

```{r}
# formula <- as.formula(paste(c("~",paste(bact_variables$key_predictors, collapse="+")), collapse=""))
# 
# red<-Hmisc::redun(formula, data=c_bact, nk=0, pr=FALSE)
# vif<-1/(1-red$rsq1)
# 
# cat("\nAvailable sample size:\n", red$n, " (", round(100*red$n/nrow(c_bact),2), "%)\n")
# 
# cat("\nVariance inflation factors:\n")
# print(round(vif,2))
# 
# cat("\nMultiple R-squared:\n")
# print(round(red$rsq1,4))



names(dat)

formula <- as.formula(paste(c("~",paste(names(dat), collapse="+")), collapse=""))

formula

red<-Hmisc::redun(formula, data = dat, nk=0, pr=FALSE)
vif<-1/(1-red$rsq1)

cat("\nAvailable sample size:\n", red$n, " (", round(100*red$n/nrow(dat),2), "%)\n")

cat("\nVariance inflation factors:\n")
print(round(vif,2))

cat("\nMultiple R-squared:\n")
print(round(red$rsq1,4))


```

#### VIF for model with key predictors and predictors of medium importance

```{r}
# formula <- as.formula(paste(c("~",paste(c(bact_variables$key_predictors,bact_variables$medimp_predictors), collapse="+")), collapse=""))
# 
# red<-Hmisc::redun(formula, data=c_bact, nk=0, pr=FALSE)
# vif<-1/(1-red$rsq1)
# 
# cat("\nAvailable sample size:\n", red$n, " (", round(100*red$n/nrow(c_bact),2), "%)\n")
# 
# cat("\nVariance inflation factors:\n")
# print(round(vif,2))
# 
# cat("\nMultiple R-squared:\n")
# print(round(red$rsq1,4))
```

#### VIF for all predictor model

```{r}
# formula <- as.formula(paste(c("~",paste(c(bact_variables$key_predictors,bact_variables$medimp_predictors, bact_variables$remaining_predictors), collapse="+")), collapse=""))
# 
# red<-Hmisc::redun(formula, data=c_bact, nk=0, pr=FALSE)
# vif<-1/(1-red$rsq1)
# 
# cat("\nAvailable sample size:\n", red$n, " (", round(100*red$n/nrow(c_bact),2), "%)\n")
# 
# cat("\nVariance inflation factors:\n")
# print(round(vif,2))
# 
# cat("\nMultiple R-squared:\n")
# print(round(red$rsq1,4))
```




#### Redundancy by parametric additive model: key predictor model

```{r}
# formula <- as.formula(paste(c("~",paste(bact_variables$key_predictors, collapse="+")), collapse=" "))
# 
# red<-Hmisc::redun(formula, data=c_bact, pr=FALSE)
# vif<-1/(1-red$rsq1)
# 
# cat("\nAvailable sample size:\n", red$n, " (", round(100*red$n/nrow(c_bact),2), "%)\n")
# 
# cat("\nVariance inflation factors:\n")
# print(round(vif,2))
# 
# cat("\nMultiple R-squared:\n")
# print(round(red$rsq1,4))
```

#### Redundancy by parametric additive model: key predictors and predictors of medium importance

```{r}
# formula <- as.formula(paste(c("~",paste(c(bact_variables$key_predictors,bact_variables$medimp_predictors), collapse="+")), collapse=""))
# 
# red<-Hmisc::redun(formula, data=c_bact,  pr=FALSE)
# vif<-1/(1-red$rsq1)
# 
# cat("\nAvailable sample size:\n", red$n, " (", round(100*red$n/nrow(c_bact),2), "%)\n")
# 
# cat("\nVariance inflation factors:\n")
# print(round(vif,2))
# 
# cat("\nMultiple R-squared:\n")
# print(round(red$rsq1,4))
```


#### Redundancy by parametric additive model: all predictors

```{r}
# For redun(), for heavily clumped predictors, linearity must be enforced
# remaining_predictors_redun <- bact_variables$remaining_predictors
# remaining_predictors_redun[remaining_predictors_redun=="BASO"] <- "I(BASO)"
# remaining_predictors_redun[remaining_predictors_redun=="EOS"] <- "I(EOS)"
# 
# formula <- as.formula(paste(c("~",paste(c(bact_variables$key_predictors,bact_variables$medimp_predictors, remaining_predictors_redun), collapse="+")), collapse=""))
# 
# red<-Hmisc::redun(formula, data=c_bact,  pr=FALSE)
# vif<-1/(1-red$rsq1)
# 
# cat("\nAvailable sample size:\n", red$n, " (", round(100*red$n/nrow(c_bact),2), "%)\n")
# 
# cat("\nVariance inflation factors:\n")
# print(round(vif,2))
# 
# cat("\nMultiple R-squared:\n")
# print(round(red$rsq1,4))
```


